# Gemini CLI 核心

Gemini CLI 的核心包（`packages/core`）是 Gemini CLI 的后端部分，负责与 Gemini API 通信、管理工具以及处理从 `packages/cli` 发送的请求。有关 Gemini CLI 的总体概述，请参阅 [主文档页面](../index.md)。

## 浏览本节内容

- **[核心工具 API](./tools-api.md)：** 有关工具如何在核心中定义、注册和使用的说明。
- **[记忆导入处理器](./memport.md)：** 使用 @file.md 语法实现的模块化 GEMINI.md 导入功能文档。

## 核心的作用

虽然 Gemini CLI 的 `packages/cli` 部分提供了用户界面，但 `packages/core` 负责以下功能：

- **Gemini API 交互：** 安全地与 Google Gemini API 通信，发送用户提示并接收模型响应。
- **提示工程：** 构建对 Gemini 模型有效的提示，可能结合对话历史、工具定义以及来自 `GEMINI.md` 文件的指导上下文。
- **工具管理与编排：**
  - 注册可用工具（例如，文件系统工具、shell 命令执行）。
  - 解释 Gemini 模型的工具使用请求。
  - 使用提供的参数执行所请求的工具。
  - 将工具执行结果返回给 Gemini 模型以进行进一步处理。
- **会话与状态管理：** 跟踪对话状态，包括历史记录和交互所需的任何相关上下文。
- **配置：** 管理核心特定的配置，例如 API 密钥访问、模型选择和工具设置。

## 安全考虑

核心在安全性方面起着至关重要的作用：

- **API 密钥管理：** 它处理 `GEMINI_API_KEY`，并确保在与 Gemini API 通信时安全使用。
- **工具执行：** 当工具与本地系统交互时（例如，`run_shell_command`），核心（及其底层工具实现）必须谨慎操作，通常涉及沙箱机制以防止意外修改。

## 聊天历史压缩

为了确保长对话不会超过 Gemini 模型的 token 限制，核心包含聊天历史压缩功能。

当对话接近所配置模型的 token 限制时，核心会在将对话发送给模型之前自动压缩对话历史。此压缩旨在在传达的信息方面保持无损，但减少了使用的 token 总数。

您可以在 [Google AI 文档](https://ai.google.dev/gemini-api/docs/models) 中找到每个模型的 token 限制。

## 模型回退

Gemini CLI 包含一个模型回退机制，以确保即使默认的 "pro" 模型受到速率限制，您也可以继续使用 CLI。

如果您正在使用默认的 "pro" 模型，并且 CLI 检测到您受到速率限制，则它会自动切换到 "flash" 模型以用于当前会话。这使您可以不间断地继续工作。

## 文件发现服务

文件发现服务负责查找项目中与当前上下文相关的文件。它被 `@` 命令及其他需要访问文件的工具所使用。

## 记忆发现服务

记忆发现服务负责查找和加载提供模型上下文的 `GEMINI.md` 文件。它以分层方式搜索这些文件，从当前工作目录开始，向上查找至项目根目录和用户主目录。它还会在子目录中进行搜索。

这样，您可以拥有全局、项目级和组件级的上下文文件，所有这些文件都会被合并，以向模型提供最相关的信息。

您可以使用 [`/memory` 命令](../cli/commands.md) 来 `显示`、`添加` 和 `刷新` 已加载的 `GEMINI.md` 文件内容。